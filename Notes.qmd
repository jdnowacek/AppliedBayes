---
title: "MT4571: Applied Bayes Notes"
format: pdf
editor: source
---

```{r}
library(nimble)
library(tidyverse)
```

## Chapter 1

from notes example with exponential data, gamma prior, gamma posterior

```{r}
post_mean <- 7/(6.6)
CI_left_bound <- qgamma(0.025,7,6.6)
CI_right_bound <- qgamma(0.975,7,6.6)
cat("The posterior mean is ", post_mean)
```

```{r}
cat("The 95% CI is (", CI_left_bound, ",", CI_right_bound, ")" )
```

```{r}
# Alternative approach through random sampling
sample_from_posterior <- rgamma(100000,7,6.6)
post_mean_sample <- mean(sample_from_posterior)
CI_left_bound_sample <- quantile(sample_from_posterior, 0.025)
CI_right_bound_sample <- quantile(sample_from_posterior, 0.975)
cat("The posterior mean from the random sample from the posterior is ", post_mean_sample)
```

```{r}
cat("The 95% CI from the random sample is (", CI_left_bound_sample, ",", CI_right_bound_sample, ")" )
```

# Gibbs Sampler

```{r}
#Example Gibbs sampler, for X~N(mu,sigma^2) when mu and sigma are unknown
# normal(phi,tau^2) prior on mu and IG on sigma^2(alpha,beta)
#Further down is code to run the example in OpenBUGS and JAGS

#Uncomment this line if you want to get the same answer each time you run it
set.seed(1293820)

#Priors
phi<-0
tau2<-1
alpha<-0.1
beta<-0.01

#Simulate some data
n<-10
x<-rnorm(n,0,1)
xbar<-mean(x)

#Number of samples to take in the chain
T<-100
#Create space to store the Markov chain in 
mu<-sigma2<-numeric(T)

#Set starting values
mu[1]<-4
sigma2[1]<-0.1

#Run the Gibbs sampler 
for(t in 1:(T-1)){
  mu[t+1]<-rnorm(1,(tau2*n*xbar + sigma2[t]*phi)/(tau2*n + sigma2[t]),
            sqrt(sigma2[t]*tau2/(tau2*n+sigma2[t])))
  sigma2[t+1]<-1/rgamma(1,shape=n/2 + alpha,
                          rate=1/2*sum((x-mu[t+1])^2) + beta)
}

#Produce trace plots of the outputs
par(mfrow=c(1,2))
plot(1:T,mu,xlab="Iteration",ylab="mu",type="l")
plot(1:T,sigma2,xlab="Iteration",ylab="sigma2",type="l")
par(mfrow=c(1,1))

#Produce density plots of the outputs
#(Note - you'd want to remove some initial samples as burn-in
# before using the samples for inference)
par(mfrow=c(1,2))
plot(density(mu))
plot(density(sigma2))
par(mfrow=c(1,1))

#Produce bivariate plot of samples
plot(mu,sigma2,type="p")

posteriormean_mu=mean(mu)
sortsample=sort(mu)
left95interval=(sortsample[2]+sortsample[3])/2
right95interval=(sortsample[97]+sortsample[98])/2
cat("posterior mean for mu=",posteriormean_mu, sep=c(""))
cat(" ", sep=c("\n"))
cat("95% credible interval=(",left95interval,",",right95interval,")", sep=c(""))

posteriormean_sigma2=mean(sigma2)
sortsample=sort(sigma2)
left95interval=(sortsample[2]+sortsample[3])/2
right95interval=(sortsample[97]+sortsample[98])/2
cat("posterior mean for sigma^2=",posteriormean_sigma2, sep=c(""))
cat(" ", sep=c("\n"))
cat("95% credible interval=(",left95interval,",",right95interval,")", sep=c(""))

# Of course, if you were to write your own code not as a very basic example, 
# but to properly perform some analysis,
# you would have to allow for a burn-in, and to also obtain additional inferences and 
# diagnostic plots 
```

# M-H Algorithm

```{r}
# Example of Metropolis sampling.
# Sampling from the standard Normal distribution. 

T<-500
#Variability of the normal distribution proposal
std<-sqrt(1) # Try 0.01,1,10,100 

#store samples
theta<-numeric(T)
#store number of acceptances
n.accept<-0

#starting value
theta[1]<-0
for (i in 1:(T-1)){
  phi<-rnorm(1,theta[i],std)  
  alpha<-min(c(1,exp(-0.5*(phi^2-theta[i]^2))))
  if(runif(1)<alpha) {
    theta[i+1]<-phi
    n.accept<-n.accept+1
  } else {
    theta[i+1]<-theta[i]
  }
}
p.accept<-n.accept/T

#Calculate effective sample size
library(coda)
chain<-mcmc(theta)
ess<-effectiveSize(chain)

#Plot using home-grown code
par(mfrow=c(1,2))
plot(1:T,theta,type="l",main=paste("p.accept=",format(p.accept,digits=2),", ESS=",format(ess,digits=1),sep=""))
qqnorm(theta)
#hist(theta)
par(mfrow=c(1,1))
acf(theta)
summary(theta)
sd(theta)

# For an analysis (rather than an illustration of the MH sampler properties)
#  remember to discard the burn-in sample. 
```

# Linear Regression

## Frequentist Approach

```{r}
data(mtcars)
#help(mtcars)

##creating a new dataframe with only mpg,drat,wt, and qsec as variables
vars=names(mtcars)%in%c("cyl", "disp", "hp", "vs","am","gear","carb") #variables to exclude
mtcars1=mtcars[!vars]
attach(mtcars1)

fit=lm(mpg~drat+wt+qsec,data=mtcars1)
summary(fit)
```

## Bayesian Approach

```{r}
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
library(nimble)
library(igraph)
library(coda)
library(R6)

n=nrow(mtcars1)
#covariates and response
y=mtcars1$mpg; drat=mtcars1$drat; wt=mtcars1$wt; qsec=mtcars1$qsec

# Specify the statistical model
cars_reCode <- nimbleCode({

# Specify the likelihood:
for(i in 1:n){
mu[i] <- beta1+beta2*drat[i]+beta3*wt[i]+beta4*qsec[i]
y[i]~dnorm(mu[i],tau)
}

# Prior for beta

beta1~dnorm(mu0,tau0)
beta2~dnorm(mu0,tau0)
beta3~dnorm(mu0,tau0)
beta4~dnorm(mu0,tau0)

tau0 <- 1/sigma02

# Prior for the precision
tau~dgamma(a, b)

# Compute the variance
sigma2 <- 1/tau
})
```

```{r}
# hyperparameters for the betas and tau
# would find n in R environment. Including here to suppress a warning
cars_reConsts <- list(mu0=0, sigma02=1000, a=0.1, b=0.1, n=32)

# list with data
cars_reData <- list(y=y,drat=drat,wt=wt,qsec=qsec)

# Initial values
cars_reInits <- list(beta1=0.5, tau = 1) # Nimble will generate the rest 

# Build and Compile the model
# to build the model
cars_re <- nimbleModel(code = cars_reCode, name = "cars_re", constants = cars_reConsts,
                    data = cars_reData, inits<-cars_reInits)

# To compile the model
Ccars_re <- compileNimble(cars_re)

# set up the monitored quantities. Default is all of the random quantities
cars_reConf <- configureMCMC(cars_re, monitors = c('beta1', 'beta2', 
              'beta3', 'beta4', 'sigma2'), enableWAIC = TRUE, print = TRUE) 

# build the MCMC algorithm
cars_reMCMC <- buildMCMC(cars_reConf)

# compile the MCMC chain 
Ccars_reMCMC <- compileNimble(cars_reMCMC, project = cars_re)
```

```{r}
####################################################################################
####### POSTERIOR SAMPLES IN CODA FORMAT TO GET MORE EASILY PLOTS AND DIAGNOSTICS  #
####################################################################################
set.seed(10)
cars_reInits <- list(list(beta1 = 0, tau = 1), 
                     list(beta1 = 1, tau = 2))
posterior <- runMCMC(Ccars_reMCMC, niter = 500000, thin=50, nburnin=100000, 
                     summary = TRUE, WAIC = TRUE, samples = TRUE, nchains=2, 
                     samplesAsCodaMCMC=TRUE, inits = cars_reInits) 
```

```{r}
combinedchains <- mcmc.list(posterior$samples$chain1, posterior$samples$chain2)
plot(combinedchains) # too many plots sometimes
```

```{r}
#plot(combinedchains[,c('beta1','beta2','sigma2')]) 
#plot(combinedchains[,'beta[1]']) # when defining a vector of parameters
autocorr.plot(posterior$samples$chain1)

autocorr.plot(posterior$samples$chain2)
```

```{r}
gelman.diag(combinedchains)

gelman.plot(combinedchains)
```

```{r}
summary(combinedchains)
```

```{r}
ESS <- t(effectiveSize(combinedchains))
cat("The Effective Sample Size is ", ESS)
```

## Variable Selection

```{r}
data(mtcars)
#help(mtcars)

##creating a new dataframe with only mpg,drat,wt, and qsec as variables
vars=names(mtcars)%in%c("cyl", "disp", "hp", "vs","am","gear","carb") #variables to exclude
mtcars1=mtcars[!vars]
attach(mtcars1)
```

```{r}
n=nrow(mtcars1)
#covariates and response
y=mtcars1$mpg; drat=mtcars1$drat; wt=mtcars1$wt; qsec=mtcars1$qsec

# Specify the statistical model
cars_reCode <- nimbleCode({

# Specify the likelihood:
for(i in 1:n){
mu[i] <- beta1 + beta2*z2*drat[i] + beta3*z3*wt[i] + beta4*z4*qsec[i]
y[i]~dnorm(mu[i],tau)
}

# Prior for beta

beta1~dnorm(mu0,tau0)
beta2~dnorm(mu0,tau0)
beta3~dnorm(mu0,tau0)
beta4~dnorm(mu0,tau0)
z2 ~ dbern(psi)  ## indicator variable associated with beta2
z3 ~ dbern(psi)  ## indicator variable associated with beta3
z4 ~ dbern(psi)  ## indicator variable associated with beta4
psi ~ dbeta(1, 1) ## hyperprior on inclusion probability

tau0 <- 1/sigma02

# Prior for the precision
tau~dgamma(a, b)

# Compute the variance
sigma2 <- 1/tau
})

# hyperparameters for the betas and tau
# would find n in R environment. Including here to suppress a warning
cars_reConsts <- list(mu0=0, sigma02=1000, a=0.1, b=0.1, n=32)

# list with data
cars_reData <- list(y=y, drat=drat, wt=wt, qsec=qsec)

# Initial values
cars_reInits <- list(beta1=0.5, beta2=0.5, beta3=0.5, beta4=0.5, tau = 1, 
                     z2=1, z3=1, z4=1, psi=0.5) # Nimble will generate the rest 

# Build and Compile the model
# to build the model
RJ_cars_re <- nimbleModel(code = cars_reCode, name = "RJ_cars_re", constants = cars_reConsts,
                    data = cars_reData, inits<-cars_reInits)
```

```{r}
# To compile the model
RJ_Ccars_re <- compileNimble(RJ_cars_re)
```

```{r}
# set up the monitored quantities. Default is all of the random quantities
RJ_cars_reConf <- configureMCMC(RJ_cars_re,  monitors = c('beta1', 'beta2',
                      'beta3', 'beta4', 'psi', 'sigma2', 'z2','z3','z4')) 
```

```{r}
configureRJ(conf = RJ_cars_reConf,     
            targetNodes = c("beta2", "beta3", "beta4"),
            indicatorNodes = c("z2", "z3", "z4"),
            control = list(mean = c(0, 0, 0), scale = 1))

RJ_cars_reConf$printSamplers()
```

```{r}
# build the MCMC algorithm
RJ_cars_reMCMC <- buildMCMC(RJ_cars_reConf)
# compile the MCMC chain 
RJ_Ccars_reMCMC <- compileNimble(RJ_cars_reMCMC, project = RJ_cars_re)
```

```{r}
set.seed(10)
RJ_cars_reInits <- list(list(beta1 = 0.5, beta2 = 0.5, beta3 = 0.5, beta4 = 0.5, tau = 1, 
                             z2=1, z3=1, z4=1, psi=0.3), 
                     list(beta1 = 1, beta2 = 1, beta3 = 1, beta4 = 1, tau = 2, 
                          z2=1, z3=1, z4=1, psi=0.8))
posterior_ind_vars <- runMCMC(RJ_Ccars_reMCMC, niter = 500000, thin=50, nburnin=100000, 
                     summary = TRUE, WAIC = FALSE, samples = TRUE, nchains=2, 
                     samplesAsCodaMCMC=TRUE, inits = RJ_cars_reInits) 
```

```{r}
posterior_ind_vars$summary$all.chains
```

```{r}
hills=read.table("hills.txt",header=TRUE)
y=hills$time; climb=hills$climb; dist=hills$dist
x=cbind(rep(1,n),climb,dist)
```

```{r}
# y[i]~dt(mu[i],tau,nu)
```

```{r}
# Specify the statistical model
hills_reCode <- nimbleCode({

# Specify the likelihood:
for(i in 1:n){
#  mu[i] <- beta1 + beta2*climb[i] + beta3*dist[i]
  y[i]~dt(mu[i],tau,nu)
  mu[i] <- inprod(beta[1:3], x[i,1:3]) 
}

# Prior for beta
for(j in 1:3){
beta[j]~dnorm(mu0,tau0)
}
#beta1~dnorm(mu0,tau0)
#beta2~dnorm(mu0,tau0)
#beta3~dnorm(mu0,tau0)
tau0 <- 1/sigma02

# Prior for the precision
tau~dgamma(a, b)

# Compute the variance
sigma2 <- 1/tau

#Prior for nu. Note, \nu does not have to be a Natural number.
nu~dgamma(c,d)
})

hills_reConsts <- list(mu0=0, sigma02=1000, a=0.1, b=0.1, c=0.1, d=0.1, n=35)

# list with data
hills_reData <- list(y=y, x=x, climb=climb,dist=dist)

# Initial values
hills_reInits <- list(tau = 1) # Nimble will generate the rest 

# Build and Compile the model
# to build the model
hills_re <- nimbleModel(code = hills_reCode, name = "hills_re", constants = hills_reConsts,
                    data = hills_reData, inits = hills_reInits)
```

```{r}
# To compile the model
Chills_re <- compileNimble(hills_re)

# set up the monitored quantities. Default is all of the random quantities
hills_reConf <- configureMCMC(hills_re, monitors = c('beta', 'sigma2', 'nu'), print = TRUE) 

# build the MCMC algorithm
hills_reMCMC <- buildMCMC(hills_reConf)
# compile the MCMC chain 
Chills_reMCMC <- compileNimble(hills_reMCMC, project = hills_re)
```

```{r}
####################################################################################
####### POSTERIOR SAMPLES IN CODA FORMAT TO GET MORE EASILY PLOTS AND DIAGNOSTICS  #
####################################################################################
set.seed(10)
hills_reInits <- list(list(tau = 1, nu = 1), 
                     list(tau = 2, nu = 1))
posterior <- runMCMC(Chills_reMCMC, niter = 60000, thin=50, nburnin=10000, 
                     summary = TRUE, WAIC = FALSE, samples = TRUE, nchains=2, 
                     samplesAsCodaMCMC=TRUE, inits = hills_reInits) 
```

```{r}
posterior$summary$all.chains
```
